{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTlo1MReaKvH",
        "outputId": "8886dcf4-6cb3-464c-b5d8-2788bb91580e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "\n",
            "\n",
            " ❌🔴❌🔴❌🔴❌🔴 BEM-VINDO AO JOGO QUIXO ❌🔴❌🔴❌🔴❌🔴 \n",
            "\n",
            "\n",
            "==================================================\n",
            "1. 👤 Jogar contra Minimax\n",
            "2. 🤖 Jogar contra Q-Learning\n",
            "3. 🧠 Treinar Q-Learning\n",
            "4. 🔄 Q-Learning vs Minimax\n",
            "5. 📊 Avaliar modelos\n",
            "6. 💾 Carregar modelo Q-Learning\n",
            "7. ❓ Ajuda\n",
            "8. 🚪 Sair\n",
            "==================================================\n",
            "Escolha uma opção: 3\n",
            "\n",
            "🧠 CONFIGURAÇÃO DO TREINAMENTO\n",
            "========================================\n",
            "\n",
            "\n",
            "👋 Programa encerrado pelo usuário.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import pickle\n",
        "import asyncio\n",
        "import threading\n",
        "import time\n",
        "from datetime import datetime\n",
        "from collections import defaultdict\n",
        "\n",
        "# Dicionários de apoio\n",
        "\n",
        "# Dicionario de posições correpondentes do tabuleiro no array\n",
        "dicio = {\n",
        "    '1,1': 0, '1,2': 1, '1,3': 2, '1,4': 3, '1,5': 4,\n",
        "    '2,1': 5, '2,2': 6, '2,3': 7, '2,4': 8, '2,5': 9,\n",
        "    '3,1': 10, '3,2': 11, '3,3': 12, '3,4': 13, '3,5': 14,\n",
        "    '4,1': 15, '4,2': 16, '4,3': 17, '4,4': 18, '4,5': 19,\n",
        "    '5,1': 20, '5,2': 21, '5,3': 22, '5,4': 23, '5,5': 24\n",
        "}\n",
        "\n",
        "# Posições inversas para traduzir índices do array para coordenadas do tabuleiro\n",
        "dicio_inverso = {v: k for k, v in dicio.items()}\n",
        "\n",
        "# Posições na borda (as únicas que podem ser movidas de acordo com as regras do Quixo)\n",
        "posicoes_borda = np.array([\n",
        "    '1,1', '1,2', '1,3', '1,4', '1,5',\n",
        "    '2,1', '2,5', '3,1', '3,5',\n",
        "    '4,1', '4,5', '5,1', '5,2', '5,3', '5,4', '5,5'\n",
        "])\n",
        "\n",
        "\n",
        "# Indices correspondentes a cada do tabuleiro no array\n",
        "dicioLinhas = {\n",
        "    'Linha 1': [0, 1, 2, 3, 4], 'Linha 2': [5, 6, 7, 8, 9], 'Linha 3': [10, 11, 12, 13, 14],\n",
        "    'Linha 4': [15, 16, 17, 18, 19], 'Linha 5': [20, 21, 22, 23, 24],\n",
        "    'Coluna 1': [0, 5, 10, 15, 20], 'Coluna 2': [1, 6, 11, 16, 21],\n",
        "    'Coluna 3': [2, 7, 12, 17, 22], 'Coluna 4': [3, 8, 13, 18, 23],\n",
        "    'Coluna 5': [4, 9, 14, 19, 24], 'Diagonal 1': [0, 6, 12, 18, 24],\n",
        "    'Diagonal 2': [4, 8, 12, 16, 20]\n",
        "}\n",
        "\n",
        "# Classe para armazenar o histórico de jogadas\n",
        "class HistoricoJogadas:\n",
        "    def __init__(self, max_jogadas=10):\n",
        "        self.jogadas = []\n",
        "        self.max_jogadas = max_jogadas\n",
        "\n",
        "    def adicionar_jogada(self, jogador, origem, destino):\n",
        "        #Marca hora em que a jogada ocorreu\n",
        "        timestamp = datetime.now().strftime(\"%H:%M:%S\")\n",
        "        jogada = {\n",
        "            \"jogador\": jogador,\n",
        "            \"origem\": origem,\n",
        "            \"destino\": destino,\n",
        "            \"timestamp\": timestamp\n",
        "        }\n",
        "        self.jogadas.append(jogada)\n",
        "        if len(self.jogadas) > self.max_jogadas:\n",
        "            self.jogadas.pop(0)\n",
        "\n",
        "    def obter_ultimas_jogadas(self, quantidade=None):\n",
        "        if quantidade is None or quantidade > len(self.jogadas):\n",
        "            return self.jogadas\n",
        "        return self.jogadas[-quantidade:]\n",
        "\n",
        "    def imprimir_historico(self):\n",
        "        print(\"\\n=== HISTÓRICO DE JOGADAS ===\")\n",
        "        for i, jogada in enumerate(self.jogadas, 1):\n",
        "            print(f\"{i}. {jogada['jogador']} moveu de {jogada['origem']} para {jogada['destino']} ({jogada['timestamp']})\")\n",
        "        print(\"===========================\\n\")\n",
        "\n",
        "# Classe do jogo\n",
        "class Jogo:\n",
        "    def __init__(self, tabuleiro=None, jogador='🔴'):\n",
        "        #Criação do tabuleiro\n",
        "        self.tabuleiro = np.full(25, \"⬜\", dtype=str) if tabuleiro is None else np.array(tabuleiro, dtype=str)\n",
        "        self.jogador_atual = jogador\n",
        "        self.historico = HistoricoJogadas()\n",
        "        self.ultima_jogada_agente = None\n",
        "\n",
        "    def turno(self):\n",
        "        return self.jogador_atual\n",
        "\n",
        "    def codificar_estado(self):\n",
        "        # Codifica o estado do jogo como uma string para usar como chave na tabela Q\n",
        "        estado_encoded = \"\"\n",
        "        for peca in self.tabuleiro:\n",
        "            if peca == \"⬜\":\n",
        "                estado_encoded += \"0\"\n",
        "            elif peca == \"🔴\":\n",
        "                estado_encoded += \"1\"\n",
        "            elif peca == \"❌\":\n",
        "                estado_encoded += \"2\"\n",
        "        return estado_encoded + \"_\" + (\"1\" if self.jogador_atual == \"🔴\" else \"2\")\n",
        "\n",
        "    # Verifica quem venceu\n",
        "    def venceu(self):\n",
        "        for nome, indices in dicioLinhas.items():\n",
        "            valores = [self.tabuleiro[i] for i in indices]\n",
        "            if all(v == \"❌\" for v in valores) or all(v == \"🔴\" for v in valores):\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    # Verifica se empatou\n",
        "    def empate(self):\n",
        "        return not self.venceu() and \"⬜\" not in self.tabuleiro\n",
        "\n",
        "    # Calcula a função de utilidade para saber o melhor estado a seguir\n",
        "    def calcular_utilidade(self, jogador):\n",
        "        if self.venceu():\n",
        "            return 1 if self.jogador_atual == jogador else -1\n",
        "\n",
        "        pontos = 0\n",
        "        for nome, indices in dicioLinhas.items():\n",
        "            valores = [self.tabuleiro[i] for i in indices]\n",
        "            if jogador == \"❌\":\n",
        "                pontos += valores.count(\"❌\") * 0.1\n",
        "                pontos -= valores.count(\"🔴\") * 0.1\n",
        "            else:\n",
        "                pontos += valores.count(\"🔴\") * 0.1\n",
        "                pontos -= valores.count(\"❌\") * 0.1\n",
        "\n",
        "        return pontos\n",
        "\n",
        "    # Gera todos os mov válidos possíveis para o jogador atual\n",
        "    def jogos_validos(self):\n",
        "        filhos = [] # Armazena todas as jogadas válidas possíveis a partir do estado atual\n",
        "        for pos in posicoes_borda: # Itera pelas posições da borda\n",
        "            i = dicio[pos] # Encontra indice correspondente a coordenada\n",
        "            if self.tabuleiro[i] == \"⬜\" or self.tabuleiro[i] == self.jogador_atual: # Verifica se é uma peça válida de ser jogada\n",
        "                for destino in self.movimentos_validos(pos): # Encontra destinos válidos para a posição\n",
        "                    novo = self.jogar((pos, destino)) # Simula a jogada e verifica se ela é válida\n",
        "                    if novo:\n",
        "                        filhos.append((pos, destino))\n",
        "        return filhos # Retorna jogadas válidas\n",
        "\n",
        "    #Fazer a jogada\n",
        "    def jogar(self, movimento):\n",
        "        origem_str, destino_str = movimento\n",
        "        origem_i, origem_j = map(int, origem_str.split(','))\n",
        "        destino_i, destino_j = map(int, destino_str.split(','))\n",
        "\n",
        "        if origem_str not in dicio or destino_str not in dicio:\n",
        "            return None\n",
        "\n",
        "        origem = dicio[origem_str]\n",
        "        destino = dicio[destino_str]\n",
        "\n",
        "        if origem_str not in posicoes_borda:\n",
        "            return None\n",
        "\n",
        "        if self.tabuleiro[origem] != \"⬜\" and self.tabuleiro[origem] != self.jogador_atual:\n",
        "            return None\n",
        "\n",
        "        novo_tabuleiro = np.array(self.tabuleiro)\n",
        "        if origem_i == destino_i:  # linha\n",
        "            linha = origem_i\n",
        "            indices = [dicio[f\"{linha},{j}\"] for j in range(1, 6)]\n",
        "            if destino_j > origem_j:\n",
        "                for k in range(0, 4):\n",
        "                    novo_tabuleiro[indices[k]] = novo_tabuleiro[indices[k + 1]]\n",
        "                novo_tabuleiro[indices[4]] = self.jogador_atual\n",
        "            else:\n",
        "                for k in range(4, 0, -1):\n",
        "                    novo_tabuleiro[indices[k]] = novo_tabuleiro[indices[k - 1]]\n",
        "                novo_tabuleiro[indices[0]] = self.jogador_atual\n",
        "        elif origem_j == destino_j:  # coluna\n",
        "            coluna = origem_j\n",
        "            indices = [dicio[f\"{i},{coluna}\"] for i in range(1, 6)]\n",
        "            if destino_i > origem_i:\n",
        "                for k in range(0, 4):\n",
        "                    novo_tabuleiro[indices[k]] = novo_tabuleiro[indices[k + 1]]\n",
        "                novo_tabuleiro[indices[4]] = self.jogador_atual\n",
        "            else:\n",
        "                for k in range(4, 0, -1):\n",
        "                    novo_tabuleiro[indices[k]] = novo_tabuleiro[indices[k - 1]]\n",
        "                novo_tabuleiro[indices[0]] = self.jogador_atual\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "        proximo_jogador = \"🔴\" if self.jogador_atual == \"❌\" else \"❌\"\n",
        "        novo_jogo = Jogo(novo_tabuleiro, proximo_jogador)\n",
        "        novo_jogo.historico = self.historico\n",
        "        return novo_jogo\n",
        "\n",
        "    def movimentos_validos(self, origem_str):\n",
        "        origem_i, origem_j = map(int, origem_str.split(','))\n",
        "        destinos = []\n",
        "\n",
        "        if origem_i == 1:\n",
        "            destinos.append(f\"5,{origem_j}\")\n",
        "        elif origem_i == 5:\n",
        "            destinos.append(f\"1,{origem_j}\")\n",
        "\n",
        "        if origem_j == 1:\n",
        "            destinos.append(f\"{origem_i},5\")\n",
        "        elif origem_j == 5:\n",
        "            destinos.append(f\"{origem_i},1\")\n",
        "\n",
        "        return destinos\n",
        "\n",
        "    #Imprime tabuleiro\n",
        "    def imprimir(self):\n",
        "        return print(\"| \" + self.tabuleiro[0] + \" | \" + self.tabuleiro[1] + \" | \" + self.tabuleiro[2]+ \" | \" + self.tabuleiro[3] + \" | \" + self.tabuleiro[4] + \" | \" + \"\\n\" +\n",
        "        \"| \" + self.tabuleiro[5] + \" | \" + self.tabuleiro[6] + \" | \" + self.tabuleiro[7]+ \" | \" + self.tabuleiro[8] + \" | \" + self.tabuleiro[9] + \" | \" + \"\\n\" +\n",
        "        \"| \" + self.tabuleiro[10] + \" | \" + self.tabuleiro[11] + \" | \" + self.tabuleiro[12]+ \" | \" + self.tabuleiro[13] + \" | \" + self.tabuleiro[14] + \" | \" + \"\\n\" +\n",
        "        \"| \" + self.tabuleiro[15] + \" | \" + self.tabuleiro[16] + \" | \" + self.tabuleiro[17]+ \" | \" + self.tabuleiro[18] + \" | \" + self.tabuleiro[19] + \" | \" + \"\\n\" +\n",
        "        \"| \" + self.tabuleiro[20] + \" | \" + self.tabuleiro[21] + \" | \" + self.tabuleiro[22]+ \" | \" + self.tabuleiro[23] + \" | \" + self.tabuleiro[24] + \" | \" + \"\\n\")\n",
        "\n",
        "# Classe para agente Q-Learning\n",
        "class QLearningAgent:\n",
        "    def __init__(self, jogador=\"❌\", alpha=0.1, gamma=0.9, epsilon=0.1, epsilon_decay=0.995, min_epsilon=0.01):\n",
        "        self.jogador = jogador\n",
        "        self.alpha = alpha  # Taxa de aprendizagem\n",
        "        self.gamma = gamma  # Fator de desconto\n",
        "        self.epsilon = epsilon  # Taxa de exploração\n",
        "        self.epsilon_decay = epsilon_decay  # Decaimento da taxa de exploração\n",
        "        self.min_epsilon = min_epsilon  # Taxa mínima de exploração\n",
        "        self.q_table = defaultdict(lambda: defaultdict(float))  # Tabela Q: {estado: {ação: valor}}\n",
        "        self.historico_estados = []  # Para aprendizagem temporal\n",
        "        self.historico_acoes = []\n",
        "        self.historico_recompensas = []\n",
        "\n",
        "    def codificar_acao(self, acao):\n",
        "        # Codifica uma ação (tupla de origem e destino) como string\n",
        "        return f\"{acao[0]}_{acao[1]}\"\n",
        "\n",
        "    def decodificar_acao(self, acao_str):\n",
        "        # Decodifica uma string de ação para tupla\n",
        "        origem, destino = acao_str.split('_')\n",
        "        return (origem, destino)\n",
        "\n",
        "    def escolher_acao(self, jogo, modo=\"treino\"):\n",
        "        # Escolhe uma ação usando epsilon-greedy ou modo de teste\n",
        "        estado = jogo.codificar_estado()\n",
        "        acoes_validas = jogo.jogos_validos()\n",
        "\n",
        "        if not acoes_validas:\n",
        "            return None\n",
        "\n",
        "        # Modo de teste: sempre escolhe a melhor ação conhecida\n",
        "        if modo == \"teste\":\n",
        "            melhor_acao = None\n",
        "            melhor_valor = float('-inf')\n",
        "\n",
        "            for acao in acoes_validas:\n",
        "                acao_str = self.codificar_acao(acao)\n",
        "                valor = self.q_table[estado][acao_str]\n",
        "                if valor > melhor_valor:\n",
        "                    melhor_valor = valor\n",
        "                    melhor_acao = acao\n",
        "\n",
        "            return melhor_acao if melhor_acao else random.choice(acoes_validas)\n",
        "\n",
        "        # Modo de treino: epsilon-greedy\n",
        "        if random.random() < self.epsilon:\n",
        "            # Exploração: ação aleatória\n",
        "            return random.choice(acoes_validas)\n",
        "        else:\n",
        "            # Exploração: melhor ação conhecida\n",
        "            melhor_acao = None\n",
        "            melhor_valor = float('-inf')\n",
        "\n",
        "            for acao in acoes_validas:\n",
        "                acao_str = self.codificar_acao(acao)\n",
        "                valor = self.q_table[estado][acao_str]\n",
        "                if valor > melhor_valor:\n",
        "                    melhor_valor = valor\n",
        "                    melhor_acao = acao\n",
        "\n",
        "            return melhor_acao if melhor_acao else random.choice(acoes_validas)\n",
        "\n",
        "    def calcular_recompensa(self, jogo_anterior, jogo_atual, acao):\n",
        "        # Calcula a recompensa para uma ação específica\n",
        "        # Recompensa básica por vitória/derrota\n",
        "        if jogo_atual.venceu():\n",
        "            if jogo_anterior.jogador_atual == self.jogador:\n",
        "                return 100  # Vitória\n",
        "            else:\n",
        "                return -100  # Derrota\n",
        "\n",
        "        if jogo_atual.empate():\n",
        "            return 0  # Empate\n",
        "\n",
        "        # Recompensas intermediárias baseadas na posição estratégica\n",
        "        recompensa = 0\n",
        "\n",
        "        # Analisa vantagens posicionais\n",
        "        for nome, indices in dicioLinhas.items():\n",
        "            valores_anterior = [jogo_anterior.tabuleiro[i] for i in indices]\n",
        "            valores_atual = [jogo_atual.tabuleiro[i] for i in indices]\n",
        "\n",
        "            # Conta peças do jogador em cada linha/coluna/diagonal\n",
        "            pecas_anteriores = valores_anterior.count(self.jogador)\n",
        "            pecas_atuais = valores_atual.count(self.jogador)\n",
        "\n",
        "            # Recompensa por formar sequências\n",
        "            if pecas_atuais > pecas_anteriores:\n",
        "                recompensa += (pecas_atuais ** 2) * 2  # Recompensa exponencial por sequências\n",
        "\n",
        "            # Penaliza por permitir sequências do oponente\n",
        "            oponente = \"🔴\" if self.jogador == \"❌\" else \"❌\"\n",
        "            pecas_oponente_anterior = valores_anterior.count(oponente)\n",
        "            pecas_oponente_atual = valores_atual.count(oponente)\n",
        "\n",
        "            if pecas_oponente_atual > pecas_oponente_anterior:\n",
        "                recompensa -= (pecas_oponente_atual ** 2) * 1.5\n",
        "\n",
        "        return recompensa\n",
        "\n",
        "    def atualizar_q_table(self, estado, acao, recompensa, proximo_estado):\n",
        "        # Atualiza a tabela Q usando a equação do Q-Learning\n",
        "        acao_str = self.codificar_acao(acao)\n",
        "\n",
        "        # Q(s,a) = Q(s,a) + α[r + γ * max Q(s',a') - Q(s,a)]\n",
        "        q_atual = self.q_table[estado][acao_str]\n",
        "\n",
        "        # Encontra o valor máximo Q para o próximo estado\n",
        "        max_q_proximo = 0\n",
        "        if proximo_estado in self.q_table:\n",
        "            max_q_proximo = max(self.q_table[proximo_estado].values()) if self.q_table[proximo_estado] else 0\n",
        "\n",
        "        # Atualização da tabela Q\n",
        "        novo_q = q_atual + self.alpha * (recompensa + self.gamma * max_q_proximo - q_atual)\n",
        "        self.q_table[estado][acao_str] = novo_q\n",
        "\n",
        "    def treinar_episodio(self, oponente_type=\"random\"):\n",
        "        # Treina um episódio completo contra um oponente\n",
        "        jogo = Jogo(jogador=self.jogador)\n",
        "        historico_experiencias = []  # (estado, ação, recompensa, próximo_estado)\n",
        "\n",
        "        max_jogadas = 50  # Evita jogos infinitos\n",
        "        contador = 0\n",
        "\n",
        "        while not jogo.venceu() and not jogo.empate() and contador < max_jogadas:\n",
        "            if jogo.turno() == self.jogador:\n",
        "                # Turno do agente Q-Learning\n",
        "                estado_atual = jogo.codificar_estado()\n",
        "                acao = self.escolher_acao(jogo, modo=\"treino\")\n",
        "\n",
        "                if acao is None:\n",
        "                    break\n",
        "\n",
        "                jogo_anterior = jogo\n",
        "                jogo = jogo.jogar(acao)\n",
        "\n",
        "                if jogo is None:\n",
        "                    break\n",
        "\n",
        "                # Calcula recompensa e armazena experiência\n",
        "                recompensa = self.calcular_recompensa(jogo_anterior, jogo, acao)\n",
        "                proximo_estado = jogo.codificar_estado()\n",
        "\n",
        "                historico_experiencias.append((estado_atual, acao, recompensa, proximo_estado))\n",
        "\n",
        "            else:\n",
        "                # Turno do oponente\n",
        "                if oponente_type == \"random\":\n",
        "                    acoes_validas = jogo.jogos_validos()\n",
        "                    if acoes_validas:\n",
        "                        acao = random.choice(acoes_validas)\n",
        "                        jogo = jogo.jogar(acao)\n",
        "                elif oponente_type == \"minimax\":\n",
        "                    acao = melhor_jogada(jogo, profundidade=2)\n",
        "                    if acao:\n",
        "                        jogo = jogo.jogar(acao)\n",
        "\n",
        "                if jogo is None:\n",
        "                    break\n",
        "\n",
        "            contador += 1\n",
        "\n",
        "        # Atualiza a tabela Q com todas as experiências do episódio\n",
        "        for estado, acao, recompensa, proximo_estado in historico_experiencias:\n",
        "            self.atualizar_q_table(estado, acao, recompensa, proximo_estado)\n",
        "\n",
        "        # Decai epsilon\n",
        "        if self.epsilon > self.min_epsilon:\n",
        "            self.epsilon *= self.epsilon_decay\n",
        "\n",
        "        # Retorna resultado do jogo\n",
        "        if jogo.venceu():\n",
        "            return \"vitoria\" if contador > 0 and historico_experiencias else \"derrota\"\n",
        "        else:\n",
        "            return \"empate\"\n",
        "\n",
        "    def salvar_modelo(self, nome_arquivo=\"q_learning_model.pkl\"):\n",
        "        # Salva o modelo Q-Learning\n",
        "        dados = {\n",
        "            'q_table': dict(self.q_table),\n",
        "            'epsilon': self.epsilon,\n",
        "            'jogador': self.jogador,\n",
        "            'alpha': self.alpha,\n",
        "            'gamma': self.gamma\n",
        "        }\n",
        "        with open(nome_arquivo, 'wb') as f:\n",
        "            pickle.dump(dados, f)\n",
        "\n",
        "    def carregar_modelo(self, nome_arquivo=\"q_learning_model.pkl\"):\n",
        "        # Carrega um modelo Q-Learning\n",
        "        try:\n",
        "            with open(nome_arquivo, 'rb') as f:\n",
        "                dados = pickle.load(f)\n",
        "\n",
        "            self.q_table = defaultdict(lambda: defaultdict(float), dados['q_table'])\n",
        "            self.epsilon = dados['epsilon']\n",
        "            self.jogador = dados['jogador']\n",
        "            self.alpha = dados['alpha']\n",
        "            self.gamma = dados['gamma']\n",
        "            return True\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Arquivo {nome_arquivo} não encontrado.\")\n",
        "            return False\n",
        "\n",
        "# Classe para treinamento e avaliação\n",
        "class TreinadorQLearning:\n",
        "    def __init__(self, agente):\n",
        "        self.agente = agente\n",
        "        self.metricas = {\n",
        "            'vitorias': 0,\n",
        "            'derrotas': 0,\n",
        "            'empates': 0,\n",
        "            'episodios': 0\n",
        "        }\n",
        "        self.historico_metricas = []\n",
        "\n",
        "    def treinar(self, num_episodios=10000, oponente=\"random\", salvar_a_cada=1000, nome_arquivo=\"q_learning_model.pkl\"):\n",
        "        # Treina o agente por um número específico de episódios\n",
        "        print(f\"🤖 Iniciando treinamento por {num_episodios} episódios contra oponente {oponente}\")\n",
        "        print(f\"💾 Salvando modelo a cada {salvar_a_cada} episódios\")\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        for episodio in range(1, num_episodios + 1):\n",
        "            resultado = self.agente.treinar_episodio(oponente_type=oponente)\n",
        "\n",
        "            # Atualiza métricas\n",
        "            if resultado == \"vitoria\":\n",
        "                self.metricas['vitorias'] += 1\n",
        "            elif resultado == \"derrota\":\n",
        "                self.metricas['derrotas'] += 1\n",
        "            else:\n",
        "                self.metricas['empates'] += 1\n",
        "\n",
        "            self.metricas['episodios'] = episodio\n",
        "\n",
        "            # Relatório de progresso\n",
        "            if episodio % 100 == 0:\n",
        "                taxa_vitoria = (self.metricas['vitorias'] / episodio) * 100\n",
        "                print(f\"Episódio {episodio}/{num_episodios} - \"\n",
        "                      f\"Vitórias: {taxa_vitoria:.1f}% - \"\n",
        "                      f\"Epsilon: {self.agente.epsilon:.3f}\")\n",
        "\n",
        "            # Salva modelo periodicamente\n",
        "            if episodio % salvar_a_cada == 0:\n",
        "                self.agente.salvar_modelo(nome_arquivo)\n",
        "                print(f\"💾 Modelo salvo no episódio {episodio}\")\n",
        "\n",
        "                # Armazena métricas históricas\n",
        "                self.historico_metricas.append({\n",
        "                    'episodio': episodio,\n",
        "                    'vitorias': self.metricas['vitorias'],\n",
        "                    'derrotas': self.metricas['derrotas'],\n",
        "                    'empates': self.metricas['empates'],\n",
        "                    'taxa_vitoria': (self.metricas['vitorias'] / episodio) * 100,\n",
        "                    'epsilon': self.agente.epsilon\n",
        "                })\n",
        "\n",
        "        # Salva modelo final\n",
        "        self.agente.salvar_modelo(nome_arquivo)\n",
        "\n",
        "        tempo_total = time.time() - start_time\n",
        "        print(f\"\\n🏁 Treinamento concluído em {tempo_total:.2f} segundos\")\n",
        "        self.imprimir_relatorio_final()\n",
        "\n",
        "    def imprimir_relatorio_final(self):\n",
        "        # Imprime relatório final do treinamento com resultados\n",
        "        total = self.metricas['episodios']\n",
        "        print(f\"\\n=== RELATÓRIO FINAL DO TREINAMENTO ===\")\n",
        "        print(f\"Total de episódios: {total}\")\n",
        "        print(f\"Vitórias: {self.metricas['vitorias']} ({(self.metricas['vitorias']/total)*100:.1f}%)\")\n",
        "        print(f\"Derrotas: {self.metricas['derrotas']} ({(self.metricas['derrotas']/total)*100:.1f}%)\")\n",
        "        print(f\"Empates: {self.metricas['empates']} ({(self.metricas['empates']/total)*100:.1f}%)\")\n",
        "        print(f\"Epsilon final: {self.agente.epsilon:.4f}\")\n",
        "        print(f\"Tamanho da tabela Q: {len(self.agente.q_table)} estados\")\n",
        "        print(\"=====================================\\n\")\n",
        "\n",
        "    def avaliar_contra_minimax(self, num_jogos=100):\n",
        "        # Avalia o agente Q-Learning contra o Minimax\n",
        "        print(f\"🔄 Avaliando Q-Learning vs Minimax em {num_jogos} jogos...\")\n",
        "\n",
        "        vitorias_q = 0\n",
        "        vitorias_minimax = 0\n",
        "        empates = 0\n",
        "\n",
        "        for jogo_idx in range(num_jogos):\n",
        "            # Alterna quem começa\n",
        "            if jogo_idx % 2 == 0:\n",
        "                resultado = self._jogar_q_vs_minimax(q_comeca=True)\n",
        "            else:\n",
        "                resultado = self._jogar_q_vs_minimax(q_comeca=False)\n",
        "\n",
        "            if resultado == \"q_venceu\":\n",
        "                vitorias_q += 1\n",
        "            elif resultado == \"minimax_venceu\":\n",
        "                vitorias_minimax += 1\n",
        "            else:\n",
        "                empates += 1\n",
        "\n",
        "            if (jogo_idx + 1) % 20 == 0:\n",
        "                print(f\"Progresso: {jogo_idx + 1}/{num_jogos} jogos\")\n",
        "\n",
        "        print(f\"\\n=== RESULTADO Q-LEARNING vs MINIMAX ===\")\n",
        "        print(f\"Q-Learning: {vitorias_q} vitórias ({(vitorias_q/num_jogos)*100:.1f}%)\")\n",
        "        print(f\"Minimax: {vitorias_minimax} vitórias ({(vitorias_minimax/num_jogos)*100:.1f}%)\")\n",
        "        print(f\"Empates: {empates} ({(empates/num_jogos)*100:.1f}%)\")\n",
        "        print(\"======================================\\n\")\n",
        "\n",
        "        return {\n",
        "            'q_learning': vitorias_q,\n",
        "            'minimax': vitorias_minimax,\n",
        "            'empates': empates,\n",
        "            'total': num_jogos\n",
        "        }\n",
        "\n",
        "    def _jogar_q_vs_minimax(self, q_comeca=True):\n",
        "        # Joga uma partida entre Q-Learning e Minimax\n",
        "        jogo = Jogo(jogador=\"🔴\" if q_comeca else \"❌\")\n",
        "        max_jogadas = 50\n",
        "        contador = 0\n",
        "\n",
        "        while not jogo.venceu() and not jogo.empate() and contador < max_jogadas:\n",
        "            if (q_comeca and jogo.turno() == \"🔴\") or (not q_comeca and jogo.turno() == \"❌\"):\n",
        "                # Turno do Q-Learning\n",
        "                acao = self.agente.escolher_acao(jogo, modo=\"teste\")\n",
        "                if acao:\n",
        "                    jogo = jogo.jogar(acao)\n",
        "            else:\n",
        "                # Turno do Minimax\n",
        "                acao = melhor_jogada(jogo, profundidade=2)\n",
        "                if acao:\n",
        "                    jogo = jogo.jogar(acao)\n",
        "\n",
        "            if jogo is None:\n",
        "                break\n",
        "\n",
        "            contador += 1\n",
        "\n",
        "        if jogo and jogo.venceu():\n",
        "            # Determina quem venceu baseado no último jogador\n",
        "            ultimo_jogador = \"❌\" if jogo.turno() == \"🔴\" else \"🔴\"\n",
        "            if (q_comeca and ultimo_jogador == \"🔴\") or (not q_comeca and ultimo_jogador == \"❌\"):\n",
        "                return \"q_venceu\"\n",
        "            else:\n",
        "                return \"minimax_venceu\"\n",
        "        else:\n",
        "            return \"empate\"\n",
        "\n",
        "# Minimax com poda alfa-beta\n",
        "def minimax(jogo, turno_max, jogador, profundidade_max=3, alfa=float(\"-inf\"), beta=float(\"inf\")):\n",
        "    if jogo.venceu() or jogo.empate() or profundidade_max == 0:\n",
        "        return jogo.calcular_utilidade(jogador)\n",
        "\n",
        "    if turno_max:\n",
        "        melhor = float(\"-inf\")\n",
        "        for movimento in jogo.jogos_validos():\n",
        "            resultado = jogo.jogar(movimento)\n",
        "            if resultado:\n",
        "                valor = minimax(resultado, False, jogador, profundidade_max - 1, alfa, beta)\n",
        "                melhor = max(melhor, valor)\n",
        "                alfa = max(alfa, melhor)\n",
        "                if beta <= alfa:\n",
        "                    break\n",
        "        return melhor\n",
        "    else:\n",
        "        pior = float(\"inf\")\n",
        "        for movimento in jogo.jogos_validos():\n",
        "            resultado = jogo.jogar(movimento)\n",
        "            if resultado:\n",
        "                valor = minimax(resultado, True, jogador, profundidade_max - 1, alfa, beta)\n",
        "                pior = min(pior, valor)\n",
        "                beta = min(beta, pior)\n",
        "                if beta <= alfa:\n",
        "                    break\n",
        "        return pior\n",
        "\n",
        "def melhor_jogada(jogo, profundidade=2):\n",
        "    movimentos = jogo.jogos_validos()\n",
        "    if not movimentos:\n",
        "        return None\n",
        "\n",
        "    if random.random() < 0.2:\n",
        "        return random.choice(movimentos)\n",
        "\n",
        "    if jogo.ultima_jogada_agente in movimentos and len(movimentos) > 1:\n",
        "        movimentos.remove(jogo.ultima_jogada_agente)\n",
        "\n",
        "    melhor_valor = float(\"-inf\")\n",
        "    melhores_movimentos = []\n",
        "\n",
        "    for movimento in movimentos:\n",
        "        resultado = jogo.jogar(movimento)\n",
        "        if resultado:\n",
        "            valor = minimax(resultado, False, jogo.turno(), profundidade)\n",
        "            if valor > melhor_valor:\n",
        "                melhor_valor = valor\n",
        "                melhores_movimentos = [movimento]\n",
        "            elif valor == melhor_valor:\n",
        "                melhores_movimentos.append(movimento)\n",
        "\n",
        "    return random.choice(melhores_movimentos) if melhores_movimentos else movimentos[0]\n",
        "\n",
        "# Funções de interface\n",
        "def mostrar_ajuda():\n",
        "    print(\"\\n=== REGRAS DO QUIXO ===\")\n",
        "    print(\"1. O tabuleiro é 5x5\")\n",
        "    print(\"2. Objetivo: formar uma linha de 5 peças do seu símbolo (horizontal, vertical ou diagonal)\")\n",
        "    print(\"3. Regras de movimento:\")\n",
        "    print(\"   - Só pode mover peças da borda\")\n",
        "    print(\"   - Só pode mover peças vazias ou suas peças\")\n",
        "    print(\"   - A peça é removida e empurrada do lado oposto\")\n",
        "    print(\"   - Sua peça sempre fica do lado para onde empurrou\")\n",
        "    print(\"4. Formato da jogada: origem destino (ex: 1,1 5,1)\")\n",
        "    print(\"======================\\n\")\n",
        "\n",
        "def menu_principal():\n",
        "    # Menu principal do jogo\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"\\n\\n ❌🔴❌🔴❌🔴❌🔴 BEM-VINDO AO JOGO QUIXO ❌🔴❌🔴❌🔴❌🔴 \\n\\n\")\n",
        "    print(\"=\"*50)\n",
        "    print(\"1. 👤 Jogar contra Minimax\")\n",
        "    print(\"2. 🤖 Jogar contra Q-Learning\")\n",
        "    print(\"3. 🧠 Treinar Q-Learning\")\n",
        "    print(\"4. 🔄 Q-Learning vs Minimax\")\n",
        "    print(\"5. 📊 Avaliar modelos\")\n",
        "    print(\"6. 💾 Carregar modelo Q-Learning\")\n",
        "    print(\"7. ❓ Ajuda\")\n",
        "    print(\"8. 🚪 Sair\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "def jogar_contra_humano(agente_tipo=\"minimax\", agente_q=None):\n",
        "    # Permite jogar contra um dos agentes\n",
        "    estado = Jogo(jogador='🔴')\n",
        "    contador_turnos = 0\n",
        "    max_turnos = 100\n",
        "\n",
        "    simbolo_agente = \"❌\"\n",
        "    nome_agente = \"Minimax\" if agente_tipo == \"minimax\" else \"Q-Learning\"\n",
        "\n",
        "    print(f\"\\n🎯 Você (🔴) vs {nome_agente} ({simbolo_agente})\")\n",
        "    print(\"🆘 Digite 'ajuda' para ver as regras\")\n",
        "    print(\"📄 Digite 'historico' para ver as últimas jogadas\")\n",
        "    print(\"🔚 Digite 'sair' para voltar ao menu\\n\")\n",
        "\n",
        "    while contador_turnos < max_turnos:\n",
        "        estado.imprimir()\n",
        "\n",
        "        if estado.venceu():\n",
        "            vencedor = '🔴' if estado.jogador_atual == '❌' else '❌'\n",
        "            print(f\"🏆 VITÓRIA DO JOGADOR {vencedor}! 🏆\")\n",
        "            estado.historico.imprimir_historico()\n",
        "            break\n",
        "        elif estado.empate():\n",
        "            print(\"🤝 EMPATE! 🤝\")\n",
        "            estado.historico.imprimir_historico()\n",
        "            break\n",
        "\n",
        "        if estado.turno() == \"🔴\":  # Turno do usuário\n",
        "            while True:\n",
        "                try:\n",
        "                    entrada = input(\"Sua jogada (origem destino): \").strip().lower()\n",
        "\n",
        "                    if entrada == \"ajuda\":\n",
        "                        mostrar_ajuda()\n",
        "                        continue\n",
        "                    elif entrada == \"historico\":\n",
        "                        estado.historico.imprimir_historico()\n",
        "                        continue\n",
        "                    elif entrada == \"sair\":\n",
        "                        return\n",
        "\n",
        "                    origem, destino = entrada.split()\n",
        "                    novo_estado = estado.jogar((origem, destino))\n",
        "\n",
        "                    if novo_estado:\n",
        "                        estado.historico.adicionar_jogada(\"🔴\", origem, destino)\n",
        "                        estado = novo_estado\n",
        "                        break\n",
        "                    else:\n",
        "                        print(\"❌ Movimento inválido! Lembre-se das regras do Quixo.\")\n",
        "                except (ValueError, IndexError):\n",
        "                    print(\"⚠️ Formato inválido. Use: 'linha,coluna linha,coluna' (ex: 1,1 5,1)\")\n",
        "        else:  # Turno do agente\n",
        "            print(f\"\\n🤖 {nome_agente} pensando...\\n\")\n",
        "\n",
        "            if agente_tipo == \"minimax\":\n",
        "                mov = melhor_jogada(estado)\n",
        "            else:  # Q-Learning\n",
        "                if agente_q is None:\n",
        "                    print(\"❌ Agente Q-Learning não carregado!\")\n",
        "                    return\n",
        "                mov = agente_q.escolher_acao(estado, modo=\"teste\")\n",
        "\n",
        "            if mov:\n",
        "                origem, destino = mov\n",
        "                print(f\"🤖 {nome_agente} move de {origem} para {destino}\\n\")\n",
        "                estado.historico.adicionar_jogada(\"❌\", origem, destino)\n",
        "                estado.ultima_jogada_agente = mov\n",
        "                estado = estado.jogar(mov)\n",
        "            else:\n",
        "                print(f\"{nome_agente} não conseguiu encontrar um movimento válido.\")\n",
        "                break\n",
        "\n",
        "        contador_turnos += 1\n",
        "\n",
        "    if contador_turnos >= max_turnos:\n",
        "        print(\"Jogo encerrado por número excessivo de turnos.\")\n",
        "\n",
        "def demonstrar_q_vs_minimax(agente_q, num_jogos=10):\n",
        "    # Demonstra jogos entre Q-Learning e Minimax\n",
        "    print(f\"\\n🔥 DEMONSTRAÇÃO: Q-Learning vs Minimax ({num_jogos} jogos)\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    treinador = TreinadorQLearning(agente_q)\n",
        "\n",
        "    for i in range(num_jogos):\n",
        "        print(f\"\\n🎮 JOGO {i+1}/{num_jogos}\")\n",
        "        print(\"-\" * 30)\n",
        "\n",
        "        # Alterna quem começa\n",
        "        q_comeca = i % 2 == 0\n",
        "        jogo = Jogo(jogador=\"🔴\" if q_comeca else \"❌\")\n",
        "        contador = 0\n",
        "        max_jogadas = 30\n",
        "\n",
        "        print(f\"{'Q-Learning (🔴)' if q_comeca else 'Minimax (🔴)'} vs {'Minimax (❌)' if q_comeca else 'Q-Learning (❌)'}\")\n",
        "\n",
        "        while not jogo.venceu() and not jogo.empate() and contador < max_jogadas:\n",
        "            jogador_atual = \"Q-Learning\" if ((q_comeca and jogo.turno() == \"🔴\") or (not q_comeca and jogo.turno() == \"❌\")) else \"Minimax\"\n",
        "\n",
        "            if jogador_atual == \"Q-Learning\":\n",
        "                acao = agente_q.escolher_acao(jogo, modo=\"teste\")\n",
        "            else:\n",
        "                acao = melhor_jogada(jogo, profundidade=2)\n",
        "\n",
        "            if acao:\n",
        "                origem, destino = acao\n",
        "                print(f\"{jogador_atual} ({jogo.turno()}): {origem} → {destino}\")\n",
        "                jogo = jogo.jogar(acao)\n",
        "\n",
        "            if jogo is None:\n",
        "                break\n",
        "            contador += 1\n",
        "\n",
        "        # Resultado\n",
        "        if jogo and jogo.venceu():\n",
        "            ultimo_jogador = \"❌\" if jogo.turno() == \"🔴\" else \"🔴\"\n",
        "            if (q_comeca and ultimo_jogador == \"🔴\") or (not q_comeca and ultimo_jogador == \"❌\"):\n",
        "                print(\"🏆 Q-Learning VENCEU!\")\n",
        "            else:\n",
        "                print(\"🏆 Minimax VENCEU!\")\n",
        "        else:\n",
        "            print(\"🤝 EMPATE!\")\n",
        "\n",
        "        if jogo:\n",
        "            jogo.imprimir()\n",
        "\n",
        "        input(\"Pressione Enter para continuar...\")\n",
        "\n",
        "def treinar_interface():\n",
        "    # Interface para treinamento do Q-Learning\n",
        "    print(\"\\n🧠 CONFIGURAÇÃO DO TREINAMENTO\")\n",
        "    print(\"=\"*40)\n",
        "\n",
        "    try:\n",
        "        episodios = int(input(\"Número de episódios (padrão: 5000): \") or \"5000\")\n",
        "        oponente = input(\"Oponente [random/minimax] (padrão: random): \").lower() or \"random\"\n",
        "        salvar_freq = int(input(\"Salvar a cada N episódios (padrão: 1000): \") or \"1000\")\n",
        "    except ValueError:\n",
        "        print(\"❌ Valores inválidos. Usando configurações padrão.\")\n",
        "        episodios = 5000\n",
        "        oponente = \"random\"\n",
        "        salvar_freq = 1000\n",
        "\n",
        "    if oponente not in [\"random\", \"minimax\"]:\n",
        "        oponente = \"random\"\n",
        "\n",
        "    print(f\"\\n🚀 Iniciando treinamento:\")\n",
        "    print(f\"📊 Episódios: {episodios}\")\n",
        "    print(f\"🎯 Oponente: {oponente}\")\n",
        "    print(f\"💾 Salvar a cada: {salvar_freq} episódios\")\n",
        "\n",
        "    confirmar = input(\"\\nContinuar? [s/N]: \").lower()\n",
        "    if confirmar != 's':\n",
        "        return None\n",
        "\n",
        "    # Cria e treina o agente\n",
        "    agente = QLearningAgent(jogador=\"❌\")\n",
        "    treinador = TreinadorQLearning(agente)\n",
        "\n",
        "    try:\n",
        "        treinador.treinar(\n",
        "            num_episodios=episodios,\n",
        "            oponente=oponente,\n",
        "            salvar_a_cada=salvar_freq\n",
        "        )\n",
        "        print(\"✅ Treinamento concluído com sucesso!\")\n",
        "        return agente\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\n⏹️ Treinamento interrompido pelo usuário.\")\n",
        "        agente.salvar_modelo(\"q_learning_parcial.pkl\")\n",
        "        print(\"💾 Modelo parcial salvo como 'q_learning_parcial.pkl'\")\n",
        "        return agente\n",
        "\n",
        "def avaliar_modelos(agente_q):\n",
        "    # Interface para avaliação de modelos\n",
        "    print(\"\\n📊 AVALIAÇÃO DE MODELOS\")\n",
        "    print(\"=\"*30)\n",
        "\n",
        "    try:\n",
        "        num_jogos = int(input(\"Número de jogos para avaliação (padrão: 100): \") or \"100\")\n",
        "    except ValueError:\n",
        "        num_jogos = 100\n",
        "\n",
        "    treinador = TreinadorQLearning(agente_q)\n",
        "    resultados = treinador.avaliar_contra_minimax(num_jogos)\n",
        "\n",
        "    # Análise estatística simples\n",
        "    taxa_vitoria_q = (resultados['q_learning'] / resultados['total']) * 100\n",
        "    taxa_vitoria_minimax = (resultados['minimax'] / resultados['total']) * 100\n",
        "\n",
        "    print(f\"\\n📈 ANÁLISE ESTATÍSTICA:\")\n",
        "    print(f\"Taxa de vitória Q-Learning: {taxa_vitoria_q:.1f}%\")\n",
        "    print(f\"Taxa de vitória Minimax: {taxa_vitoria_minimax:.1f}%\")\n",
        "\n",
        "    if taxa_vitoria_q > taxa_vitoria_minimax:\n",
        "        print(\"🎯 Q-Learning demonstrou desempenho superior!\")\n",
        "    elif taxa_vitoria_minimax > taxa_vitoria_q:\n",
        "        print(\"🎯 Minimax demonstrou desempenho superior!\")\n",
        "    else:\n",
        "        print(\"🤝 Desempenho equilibrado entre os algoritmos!\")\n",
        "\n",
        "    return resultados\n",
        "\n",
        "# Execução principal do jogo\n",
        "if __name__ == \"__main__\":\n",
        "    agente_qlearning = None\n",
        "\n",
        "    while True:\n",
        "        menu_principal()\n",
        "\n",
        "        try:\n",
        "            opcao = input(\"Escolha uma opção: \").strip()\n",
        "\n",
        "            if opcao == '1':\n",
        "                jogar_contra_humano(\"minimax\")\n",
        "\n",
        "            elif opcao == '2':\n",
        "                if agente_qlearning is None:\n",
        "                    print(\"❌ Nenhum agente Q-Learning carregado!\")\n",
        "                    print(\"💡 Carregue um modelo (opção 6) ou treine um novo (opção 3)\")\n",
        "                else:\n",
        "                    jogar_contra_humano(\"qlearning\", agente_qlearning)\n",
        "\n",
        "            elif opcao == '3':\n",
        "                agente_qlearning = treinar_interface()\n",
        "\n",
        "            elif opcao == '4':\n",
        "                if agente_qlearning is None:\n",
        "                    print(\"❌ Nenhum agente Q-Learning carregado!\")\n",
        "                    print(\"💡 Carregue um modelo (opção 6) ou treine um novo (opção 3)\")\n",
        "                else:\n",
        "                    try:\n",
        "                        num = int(input(\"Quantos jogos demonstrar? (padrão: 5): \") or \"5\")\n",
        "                        demonstrar_q_vs_minimax(agente_qlearning, num)\n",
        "                    except ValueError:\n",
        "                        demonstrar_q_vs_minimax(agente_qlearning, 5)\n",
        "\n",
        "            elif opcao == '5':\n",
        "                if agente_qlearning is None:\n",
        "                    print(\"❌ Nenhum agente Q-Learning carregado!\")\n",
        "                else:\n",
        "                    avaliar_modelos(agente_qlearning)\n",
        "\n",
        "            elif opcao == '6':\n",
        "                nome_arquivo = input(\"Nome do arquivo (padrão: q_learning_model.pkl): \").strip()\n",
        "                if not nome_arquivo:\n",
        "                    nome_arquivo = \"q_learning_model.pkl\"\n",
        "\n",
        "                agente_qlearning = QLearningAgent()\n",
        "                if agente_qlearning.carregar_modelo(nome_arquivo):\n",
        "                    print(f\"✅ Modelo carregado com sucesso de {nome_arquivo}\")\n",
        "                    print(f\"📊 Estados na tabela Q: {len(agente_qlearning.q_table)}\")\n",
        "                    print(f\"🎯 Epsilon atual: {agente_qlearning.epsilon:.4f}\")\n",
        "                else:\n",
        "                    print(f\"❌ Erro ao carregar modelo de {nome_arquivo}\")\n",
        "                    agente_qlearning = None\n",
        "\n",
        "            elif opcao == '7':\n",
        "                mostrar_ajuda()\n",
        "\n",
        "            elif opcao == '8':\n",
        "                print(\"👋 Obrigado por jogar! Até a próxima!\")\n",
        "                break\n",
        "\n",
        "            else:\n",
        "                print(\"❌ Opção inválida! Escolha um número de 1 a 8.\")\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\n\\n👋 Programa encerrado pelo usuário.\")\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Erro inesperado: {e}\")\n",
        "            print(\"🔄 Retornando ao menu principal...\")\n",
        "\n",
        "        input(\"\\nPressione Enter para continuar...\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}